{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Análise de Vendas de Rede de Lojas"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Índice da Análise"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "1. Business Problem\n",
                "    * Starting Context\n",
                "        * Business Understanding\n",
                "2. Starting Phase\n",
                "    * CRISP-DS\n",
                "3. Analysis Phase\n",
                "    * Data Collection\n",
                "    * Data Cleaning\n",
                "        * Feature Extraction\n",
                "    * Data Analysis\n",
                "        * Descriptive Data Analysis\n",
                "        * Hypotheses Mindmap\n",
                "        * Exploratory Data Analysis\n",
                "4. Model Phase\n",
                "    * Feature Engineering\n",
                "        * Data Preparation\n",
                "        * Feature Selection\n",
                "    * Model Building\n",
                "        * Train-Test Splitting\n",
                "        * Model Selection\n",
                "            * Baseline Training\n",
                "            * Cross Validation Training\n",
                "            * Models Performance\n",
                "    * Model Evaluation\n",
                "        * Model Hyperparameter Fine Tuning\n",
                "        * Metrics Interpretation\n",
                "            * Business Metrics\n",
                "            * Model Metrics\n",
                "5. Deployment Phase\n",
                "    * Visualization and Dashboard\n",
                "        * Performance Assessment\n",
                "        * Model Performance\n",
                "            * Baseline vs Model Performance\n",
                "            * Model Performance in Business\n",
                "        * Business Performance Gain\n",
                "    * API development\n",
                "        * Prediction Class\n",
                "        * API Handler\n",
                "        * API Tester\n",
                "    * Web App\n",
                "        * Frontend"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Business Problem"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Starting Context"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\"contexto inicial aqui\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### Business Understanding"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "É possível entender o problema de negócio fazendo apenas 4 perguntas, estas são:"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "* Qual a Motivação?\n",
                "    - Qual o contexto?\n",
                "* Qual a causa raiz do problema?\n",
                "    - Porque fazer uma análise de vendas e não outra coisa?\n",
                "* Quem é o dono do problema?\n",
                "    - Quem precisa dessa solução? Gerentes, CFO? Quem vai nos cobrar?\n",
                "* Qual o formato da solução de deploy?\n",
                "    - Granularidade:\n",
                "        - Qual o alcance esperado para se fazer essa análise?\n",
                "        - Análise feita semanal, diária, mensal, por loja, por cidade etc\n",
                "    - Tipo de Análise:\n",
                "        - Será regressão, classificação, clustering, etc\n",
                "    - Potenciais Métodos:\n",
                "        - Podemos supor que vai ser usado qual algoritmo? random forest, regressão linear, KNN, Cross Validation, etc\n",
                "    - Formato de deploy:\n",
                "        - Aplicação web, aplicação mobile, bot do Telegram, Docker, Heroku, AWS, etc"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "No nosso caso, as respostas para as perguntas acima são:"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "* Qual a motivação?\n",
                "* Qual a causa raiz do problema?\n",
                "* Quem é o dono do problema?\n",
                "* Qual o formato da solução de deploy?\n",
                "    - Granularidade:\n",
                "    - Tipo de Análise:\n",
                "    - Potenciais Métodos:\n",
                "    - Formato de deploy:\n",
                "        - Pedrições acessadas via celular.\n",
                "        - Utilizar API do Telegram.\n",
                "        - Predições acessadas via web\n",
                "        - Aplicação web"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Starting Phase"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Na fase inicial do projeto importamos as bibliotecas necessárias, fazemos as configurações iniciais do notebook e de algumas bibliotecas.\n",
                "\n",
                "Com ela bem feita vamos ter tudo pronto para seguir a análise bem configurada e reprodutível para outras pessoas."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    # Fundamental Analytics libraries\n",
                "    import pandas as pd\n",
                "    import seaborn as sns\n",
                "    import numpy as np\n",
                "    from matplotlib import pyplot as plt\n",
                "    from scipy import stats as sts\n",
                "    from sklearn.preprocessing import RobustScaler, MinMaxScaler, LabelEncoder\n",
                "    # Toolbox libraries\n",
                "    import time\n",
                "    import math\n",
                "    import pickle\n",
                "    import random\n",
                "    import requests\n",
                "    import inflection\n",
                "    import warnings\n",
                "    from operator import itemgetter as pick\n",
                "    from datetime import datetime, timedelta\n",
                "    from loguru import logger as log\n",
                "    from IPython.display import Image\n",
                "    from IPython.core.display import HTML\n",
                "    # Model libraries\n",
                "    from boruta import BorutaPy\n",
                "    from sklearn.linear_model import LinearRegression, Lasso\n",
                "    from sklearn.ensemble import RandomForestRegressor\n",
                "    from xgboost import XGBRegressor\n",
                "    import xgboost\n",
                "    from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
                "    # Initial configurations\n",
                "    warnings.filterwarnings('ignore')\n",
                "    warnings.simplefilter(action = 'ignore', category = FutureWarning)\n",
                "    xgboost.set_config(verbosity = 0)\n",
                "    # Info about imports\n",
                "    print(\"Import successful\")\n",
                "    #log.info(\"Import successful\")\n",
                "    \n",
                "except Exception as e:\n",
                "    print(\"Error while importing libraries: \", \"/n\", e)\n",
                "    #log.error(\"Error while importing libraries: \", e) "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Start = datetime.now() # time object"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## CRISP-DS"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Image(filename='..\\\\..\\\\Assets\\\\Images\\\\Data Science Project Cycle.png', width=600, height=550)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Cross-Industry Standard Process for Data Science é um método cíclico de desenvolvimento\n",
                "- Desde o primeiro ciclo vamos ter uma versão end-to-end da solução\n",
                "- Vamos passar pelas etapas da análise várias vezes\n",
                "- Temos mais velocidade na entrega de valor\n",
                "- Conseguimos mapear os possíveis problemas"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### Procedimento padrão dos projetos de Data Science"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Image(filename='..\\\\..\\\\Assets\\\\Images\\\\Data Science Project Guide.png')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Dataset"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Files\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Descrição dos arquivos de entrada: "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Data fields"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Descrição das colunas do arquivo CSV que serão utilizadas no projeto."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Analysis Phase"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Image(filename='..\\\\..\\\\Assets\\\\Images\\\\Analysis Phase.png', width=250, height=100)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Data Collection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Image(filename='..\\\\..\\\\Assets\\\\Images\\\\Data Collection.png', width=200, height=100)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Como neste projeto não vamos usar comunicação com API ou SQL, vamos carregar os dados a partir de um arquivo .CSV"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Loading Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    df_sales_raw = pd.read_csv('..\\\\..\\\\..\\\\Data\\\\Dataset\\\\Raw\\\\train.csv', low_memory=False)\n",
                "    df_stores_raw = pd.read_csv('..\\\\..\\\\..\\\\Data\\\\Dataset\\\\Raw\\\\store.csv', low_memory=False)\n",
                "    print(\"Loading successful\")\n",
                "    df_raw = pd.merge(df_sales_raw, df_stores_raw, how = \"left\", on = \"Store\")\n",
                "    print(\"Merge successful\")\n",
                "    #log.info(\"Merge successful\")\n",
                "except Exception as e:\n",
                "    print(\"Error while merging: \", \"/n\", e)\n",
                "    #log.error(\"Error while merging: \", e) "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Data Cleaning"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Image(filename='..\\\\..\\\\Assets\\\\Images\\\\Data Cleaning.png', width=200, height=100)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Data Cleaning Checkpoint"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Fazendo um checkpoint, isolanmos os resultados obtidos nesta seção dentro dela e evitamos propagações de erros que requeiram a reexecução do notebook inteiro."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df1 = df_raw.copy()\n",
                "print(\"Checkpoint successful\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df1.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Rename Columns"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Vamos mudar as colunas para nomes mais significativos, visto que a partir dos dados brutos os nomes vem ideais para quem desenvolveu seu armazenamento, mas não para quem vai usar os dados numa análise futura.\n",
                "\n",
                "Com isso os nomes ficam mais intuitivos e mais fluídos de entender ao longo da análise."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "col_df, colunas = get_column_names(df1)\n",
                "col_df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "snakecase = lambda column: inflection.underscore(column) \n",
                "Colunas_new = list(map(snakecase, colunas))\n",
                "df1.columns = Colunas_new\n",
                "# df1.columns\n",
                "col_df, colunas = get_column_names(df1)\n",
                "col_df"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Data Dimensions"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Descobrir o tamanho o Dataset e conhecer as dimensões de com o que estamos trabalhando."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Data Types"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Verificar os tipos de dados e se necessitam de alguma transformação para tornar o processamento mais eficiente ou mesmo possível."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Missing values"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Vamos verificar se há dados faltantes no dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "missing_values, missing_columns_names = get_broadview_miss_val(df1)\n",
                "missing_values"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, ax = plt.subplots(figsize=(12, 8))\n",
                "\n",
                "sns.heatmap(df1.isnull(), yticklabels=False, cbar=False, cmap='magma', ax=ax)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Existem três maneiras de tratar nossos dados faltantes:\n",
                "- Descartando completamente os dados faltantes\n",
                "- Utilizando o próprio comportamento da coluna para substituir os dados faltantes, utilizando de média ou mediana\n",
                "- Entendimento do negócio, utilizando algumas regras que podem ter passado despercebidas para substituir os dados faltantes a partir de um método mais específico para este dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "missing_columns_names"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Esta é uma das partes mais críticas da análise pois se os dados faltantes forem muitos, o método de substituição deles pode ser determinante no sucesso ou fracasso do modelo nas seções mais abaixo.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Conferência final dos valores faltantes:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "missing_values1, missing_columns_names1 = get_broadview_miss_val(df1)\n",
                "missing_values1"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Type Conversion"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Após algumas transformações, os tipos de dados das colunas podem mudar sem sabermos, então vamos verificar o estado atual das colunas e checar se precisamos fazer alguma conversão."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "get_dataset_types(df1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df1.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "get_dataset_types(df1)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Feature Extraction"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Variable Filtering"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Vamos filtrar as variáveis para deixar o dataset mais leve e de acordo com as possíveis restrições de negócio que encontrarmos."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df1.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Row Filtering"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Column Filtering"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Data Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Image(filename='..\\\\..\\\\Assets\\\\Images\\\\Data Analysis.png', width=200, height=100)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Data Analysis Checkpoint"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Fazendo um checkpoint, copiamos o dataframe para uma nova variável, isolando os resultados obtidos nesta seção dentro dela e evitando propagações de erros que requeiram a reexecução do notebook inteiro."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df2 = df1.copy()\n",
                "print(\"Checkpoint successful\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df2.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Descriptive Data Analysis"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Na análise descritiva vamos entender"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "get_dataset_types(df2)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "num_attributes = df2.select_dtypes(include=['int64','float64'])\n",
                "cat_attributes = df2.select_dtypes(exclude=['int32','int64','float64', 'datetime64[ns]'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "num_attributes.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cat_attributes.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Numerical Attributes"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Vamos analisar os atributos numéricos:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "get_num_statistics_metrics(num_attributes)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Categorical Attributes"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Vamos analisar os atributos categóricos:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "get_unique_cat_values(cat_attributes)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Hypotheses Mindmap"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Para chegarmos na Análise Exploratória de Dados e sabermos por qual caminho vamos nos guiar, vamos fazer uma lista de hipóteses a partir de três perguntas para analisar na próxima parte do projeto:\n",
                "\n",
                "- Qual o fenômeno modelado?\n",
                "- Quais são os agentes que atuam sobre o fenômeno de interesse?\n",
                "- Quais são os atributos dos agentes?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Image(filename='..\\\\..\\\\Assets\\\\Images\\\\Hypotheses Mindmap.png', width=900, height=500)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Hypotheses Questions"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Qual o fenômeno modelado?\n",
                "- Quais são os agentes que atuam sobre o fenômeno de interesse?"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Quais são os atributos dos agentes?"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Selected Hypotheses List"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Esta é a lista final de hipóteses que vamos procurar confirmar ou falsear com a análise exploratória de dados, a partir das conclusões dessas hipóteses vamos ter uma idéia melhor de como vamos construir o modelo de previsão de vendas."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exploratory Data Analysis"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Vamos listar primeiro quais os objetivos que queremos alcançar com a análise exploratória de dados."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Objectives"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Ganhar experiência de negócio\n",
                "- Validar hipóteses de negócio\n",
                "- Perceber quais variáveis são importantes para o modelo\n",
                "- Gerar Insigths sobre o negócio "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### Insights"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Os insights de dados referem-se à compreensão profunda que um indivíduo ou empresa obtém ao analisar seus dados sobre um problema específico de negócio.\n",
                "\n",
                "Essa compreensão profunda ajuda empresas a tomarem melhores decisões do que aquelas que se baseiam somente no instinto."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Insights podem ser gerados de duas formas:\n",
                "- Surpresa\n",
                "    - Uma conclusão nova surge através dos dados\n",
                "- Quebra de crenças\n",
                "    - Quando uma crença empírica sobre o negócio é refutada, e provada que na verdade era o inverso ou que era completamente inválida e sem base sólida"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### Processes"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Quais são os processos que vamos utilizar para analisar os dados?"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Análise Univariada\n",
                "- Análise Bivariada\n",
                "- Análise Multivariada"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Qual o objetivo de cada processo?"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Análise Univariada\n",
                "    - Como é essa variável?\n",
                "    - Mínimos, máximos, distribuição, range\n",
                "- Análise Bivariada\n",
                "    - Como essa variável impacta na variável alvo?\n",
                "    - Correlação, validação de hipóteses\n",
                "- Análise Multivariada\n",
                "    - Como as variáveis se relacionam?\n",
                "    - Correlação, validação de hipóteses"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Univariate Analysis"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Vamos analisar as variáveis de forma univariada, ou seja, vamos analisar apenas uma variável por vez, sem relação com outras."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### Target Variable"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Vamos analisar a variável alvo, ou seja, a variável que queremos prever."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "target = \"\"\n",
                "sns.distplot(df2[target]).set_title(f'Distribution of {target}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sns.distplot(df2[target], kde=False, bins=30).set_title(f'Distribution of {target}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### Numerical Variables"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Vamos analisar as características das variáveis numéricas."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "num_attributes = df2.select_dtypes(include=['int64','float64'])\n",
                "num_attributes.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig = plt.figure(figsize = (30,15))\n",
                "ax = fig.gca()\n",
                "num_attributes.hist(ax = ax,bins=25)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Conclusões nessa fase:"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "Quanto as outras, precisamos compará-las com outras variáveis para tirar conclusões mais consistentes."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### Categorical Variables"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Vamos analisar as características das variáveis categóricas."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Bivariate Analysis"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "A partir daqui começamos a tirar conclusões mais consistentes sobre as nossas hipóteses. Vamos testar uma por uma e ver quais se confirmam."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### H1"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### H2"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### H3"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### H4"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### H5"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Hypotheses Validation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "conclusions =  [['H1', 'Falsa', 'Baixa', 'Sim'],  \n",
                "                ['H2', 'Verdadeira', 'Média', 'Não'],\n",
                "                ['H3', 'Verdadeira', 'Alta', 'Não'],\n",
                "                ['H4', 'Verdadeira', 'Média', 'Possível'] ]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Hypotheses = get_analysis_conclusions(conclusions, columns_included = False)\n",
                "Hypotheses"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Multivariate Analysis"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### Numerical Attributes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "num_attributes.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "correlation = num_attributes.corr(method='pearson')\n",
                "sns.heatmap(correlation, annot=True)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### Categorical Attributes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cat_attributes.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cat = df2.select_dtypes(include='object')\n",
                "cat.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Model Phase"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Image(filename='..\\\\..\\\\Assets\\\\Images\\\\Model Phase.png', width=250, height=100)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Feature Engineering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Image(filename='..\\\\..\\\\Assets\\\\Images\\\\Feature Engineering.png', width=200, height=100)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Feature Engineering Checkpoint"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Fazendo um checkpoint, copiamos o dataframe para uma nova variável, isolando os resultados obtidos nesta seção dentro dela e evitando propagações de erros que requeiram a reexecução do notebook inteiro."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df3 = df2.copy()\n",
                "print(\"Checkpoint successful\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df3.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Objectives"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "O Feature Engineering serve para transformar os dados em um formato que pode ser utilizado pelo modelo.\n",
                "\n",
                "O Feature Engineering é o último processo que lida com o dataset antes dele ser utilizado pelo modelo, e é composto principalmente de duas partes:\n",
                "- Data Preparation\n",
                "- Feature Selection"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Data Preparation"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Na fase de Data Preparation, o dataset é tratado para que possamos utilizá-lo no modelo, essa fase é composta de quatro partes:\n",
                "- Tratamento de variáveis numéricas\n",
                "    - Normalização\n",
                "        - Rescala o centro dos dados para zero com desvio padrão igual a 1\n",
                "        - Funciona melhor para dados que já possuem uma distribuição normal\n",
                "    - Rescaling\n",
                "        - Rescala os dados para um intervalo de valores entre 0 e 1\n",
                "        - Funciona melhor para dados que não possuem uma distribuição normal\n",
                "- Tratamento de variáveis categóricas\n",
                "    - Encoding\n",
                "        - Transforma dados categóricos em dados numéricos\n",
                "        - Existem vários tipos de encoding, como:\n",
                "            - One-Hot Encoding\n",
                "            - Label Encoding\n",
                "            - Ordinal Encoding\n",
                "- Tratamento de variáveis cíclicas\n",
                "    - Transformação de Seno e Cosseno\n",
                "        - Preserva a natureza cíclica dos dados\n",
                "- Tratamento da variável resposta\n",
                "    - Rescalam os valores da variável resposta de modo a ter uma distribuição mais próxima da normal\n",
                "        - Transformação logarítmica\n",
                "        - Transformação Box-Cox\n",
                "        - Transformação Square Root\n",
                "        - Transformação Cube Root"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Numerical Variable Treatment"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### Normalization"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Se tivermos dados que possuem uma distribuição normal, podemos normalizar os dados para que o centro seja zero e o desvio padrão seja igual a 1.\n",
                "\n",
                "Se pela análise univariada um dado não possui uma distribuição normal, eles não se encaixa no processo de normalização."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### Rescaling"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Se tivermos dados que não possuem uma distribuição normal, podemos rescalar os dados para que o intervalo deles fique entre 0 e 1."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Tipos de rescaling:\n",
                "- Min-Max Scaler\n",
                "    - Muito sensível a outliers\n",
                "    - Pode distorcer os dados rescalados por conta do peso dos outliers\n",
                "- Robust Scaler\n",
                "    - Considera os quartis individualmente\n",
                "    - Elimina a sensibilidade a outliers"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Portanto vamos aplicar o Robust Scaler para as que tem mais outliers e o Min-Max Scaler para as que tem menos outliers."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### Robust Scaler"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Vamos selecionar as colunas numéricas para aplicar o Robust Scaler:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#select all numeric columns\n",
                "# numerical_data = df3.select_dtypes(include=[np.number]).copy()\n",
                "numerical_data = df3.select_dtypes(include=['int64', 'int32', 'float64', 'float32']).copy()\n",
                "numerical_data.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "numerical_data.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "numerical_columns = numerical_data.columns\n",
                "numerical_columns"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Vamos rescalar as colunas numéricas:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Vamos verificar os outliers dessas colunas:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "rs = RobustScaler()\n",
                "mms = MinMaxScaler()\n",
                "\n",
                "# rescale robust\n",
                "target1 = \"\"\n",
                "target2 = \"\"\n",
                "numerical_data[target1] = rs.fit_transform(numerical_data[[target1]].values)\n",
                "#pickle.dump(rs, open('..//..//..//Data//Scalers/target1.pkl', 'wb'))\n",
                "\n",
                "# rescale minmax\n",
                "numerical_data[target2] = mms.fit_transform(numerical_data[[target2]].values)\n",
                "#pickle.dump(mms, open('..//..//..//Data//Scalers/target2.pkl', 'wb'))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Neste caso os scalings não vão se apresentar diretamente no dataset, mas vão ser aplicados nele durante o processo de treinamento do modelo. Eles estão sendo salvos como arquivo pickle para serem chamados no próximo passo."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Categorical Variable Treatment"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### Encoding"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Se tivermos dados categóricos, podemos transformá-los em dados numéricos para o modelo entender e processar a previsão."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Tipos de encoding:\n",
                "- One-Hot Encoding\n",
                "    - Transformação de natureza usada com dados de classificação específica, como tipos, tamanhos e cores\n",
                "- Label Encoding\n",
                "    - Transformação de natureza usada com dados não cíclicos e específicos, como nomes de estados e cidades\n",
                "- Ordinal Encoding\n",
                "    - Transformação de natureza usada com dados sequenciais, como classes, graus de importância, etc."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### One-Hot Encoding"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Vamos selecionar as colunas categóricas para aplicar o One-Hot Encoding:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "categorical_data = df3.select_dtypes(exclude=['int64', 'int32', 'float64', 'float32']).copy()\n",
                "categorical_data.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Sobraram muitas datas como tipo 'object', mas datas não são consideradas categóricas e sim dados cíclicos ou temporais. Portanto vamos dropar as colunas que apresentam datas e ficar apenas com as colunas categóricas."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "remaining_columns = categorical_data.columns\n",
                "remaining_columns"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "remaining_columns = Flexlist(remaining_columns)\n",
                "type(remaining_columns)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "temporal_columns = remaining_columns[[0, 4, 5, 6]]\n",
                "temporal_columns"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "categorical_columns = remaining_columns[[1,2,3]]\n",
                "categorical_columns"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Vamos ver o resultado ao dropar as colunas temporais:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "categorical_data.drop(temporal_columns, axis=1, inplace=True)\n",
                "categorical_data.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Agora vamos realizar o One-Hot Encoding:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "categorical_data = pd.get_dummies(categorical_data, prefix = ['target_name'], columns = ['target_column_name'])\n",
                "categorical_data.sample(10)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Esse é um dos tipos de encoding que vemos ser aplicado diretamente no dataset."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### Label Encoding"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "le = LabelEncoder()\n",
                "\n",
                "categorical_data['store_type'] = le.fit_transform(categorical_data['store_type'])\n",
                "#pickle.dump(le, open('..//..//..//Data//Encoders/store_type_encoder.pkl', 'wb'))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Neste caso o encoding não vai se apresentar diretamente no dataset, mas vai ser aplicado nele durante o processo de treinamento do modelo. Ele está sendo salvo como arquivo pickle para ser chamado no próximo passo."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### Ordinal Encoding"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "assortment_dict = {'Basic': 1, 'Extra': 2, 'Extended': 3}\n",
                "categorical_data['assortment'] = categorical_data['assortment'].map(assortment_dict)\n",
                "categorical_data.sample(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "categorical_data.shape"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Neste caso o encoding se apresenta diretamente no dataset."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Cyclic Variable Treatment"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Vamos aplicar o encoding de Seno e Cosseno para as colunas com dados cíclicos ou temporais:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "temporal_data = df3[[*temporal_columns,'day','month','day_of_week','week_of_year']].copy()\n",
                "temporal_data.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "temporal_data.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "temporal_data.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Neste caso o encoding se apresenta diretamente no dataset, criando novas colunas e alterando os dados a partir das colunas originais."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Target Variable Treatment"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Vamos aplicar o encoding logarítmico para a variável resposta:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "numerical_data['sales'] = np.log1p(numerical_data['sales'])\n",
                "numerical_data['sales'].head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Neste caso o encoding se apresenta diretamente no dataset."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Encoded Dataset"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Agora vamos fundir os três datasets que criamos durante o rescaling e encoding das variáveis para obter o dataset tratado para o treinamento do modelo:"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Vamos conferir os formatos de cada dataset para assegurar que nenhuma **linha** foi adicionada, pois isso tornaria impossível a fusão dos datasets já que perderíamos o índice correto para fundir.\n",
                "\n",
                "A idéia do Feature Engineering no geral é aumentar o número de **colunas** para encodar as variáveis categóricas e criar rescalers para aplicação nas variáveis numéricas."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "formats = get_feature_engineering_formats(  [numerical_data, categorical_data, temporal_data],\n",
                "                                            ['numerical_data', 'categorical_data', 'temporal_data'])\n",
                "formats"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### Dataset Fusion"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Com os formatos compatíveis e mesmo número de linhas, vamos fazer a fusão dos datasets:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "encoded_dataset = get_encoded_dataset([numerical_data, categorical_data, temporal_data])\n",
                "encoded_dataset.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "encoded_dataset.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "non_eligible_cols = ['week_of_year', 'day', 'month', 'day_of_week', 'promo_since', 'competition_since', 'year_week' ]\n",
                "encoded_dataset = encoded_dataset.drop(non_eligible_cols, axis=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "encoded_dataset.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "encoded_dataset.shape"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Graças ao encoding e rescaling, ganhamos uma quantidade considerável de colunas no dataset tratado, mas filtramos uma última vez para remover colunas redundantes que foram usadas para criar outras."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### Encoded Dataset Storage"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Vamos salvar o dataset tratado para carregar novamente quando necessário"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "save_dataset(encoded_dataset, name = \"Dataset_Encoded\")\n",
                "#test = load_dataset('..//..//..//Data//Dataset//Dataset_Encoded.csv')\n",
                "#test.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#test.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Feature Selection"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Agora vamos selecionar as variáveis que vamos utilizar para o treinamento do modelo, o principal objetivo é eliminar variáveis linearmente dependentes de outras, pois quanto mais colunas mais confuso o modelo pode ficar em chegar a uma conclusão, e informações redundantes não ajudam nisso."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Para realizar o Feature Selection existem alguns métodos:\n",
                "- PCA - Principal Component Analysis\n",
                "- Lasso - Least Absolute Shrinkage and Selection Operator\n",
                "- Random Forest - Random Forest Classifier\n",
                "- Extrative Feature Selection - Extrative Feature Selection\n",
                "- Feature Importance - Feature Importance\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# training and test dataset for Boruta\n",
                "#need to pass numpy arrays, not dataframes\n",
                "#for this we use the .values attribute and the ravel method\n",
                "#X_train_n = X_train.values\n",
                "#y_train_n = y_train.values.ravel() #ravel method returns a flattened array\n",
                "\n",
                "# define RandomForestRegressor\n",
                "#rf = RandomForestRegressor(n_jobs=-1)\n",
                "\n",
                "# Train Boruta\n",
                "#boruta = BorutaPy(rf, n_estimators='auto', verbose=2, random_state=42).fit(X_train_n, y_train_n)\n",
                "#feature_selection_cols = boruta.support_.tolist() #returns a dataframe with the selected columns"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Best Features"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Com as colunas mais importantes separadas, vamos verificar se alguma coluna não ficou de fora quando comparado com nossas conclusões na fase da análise exploratória, e também ver o quanto as colunas escolhidas pelo algoritmo se aproximam das conclusões da análise."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Final Dataset Storage"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Vamos salvar o dataset final para carregar novamente quando necessário."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "encoded_dataset[feature_selection].head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_dataset = encoded_dataset[feature_selection]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_dataset.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "save_dataset(model_dataset, name = \"Dataset_Model\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import gc\n",
                "gc.collect()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Com isso temos nosso dataset final salvo em um arquivo CSV."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Model Building"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Image(filename='..\\\\..\\\\Assets\\\\Images\\\\Model Building.png', width=200, height=100)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "A parte de Model Building é composta principalmente por três partes:\n",
                "- Train-Test Splitting\n",
                "   - Vamos separar o dataset em treino e teste, descartando as variáveis resposta\n",
                "- Model Selection\n",
                "    - Baseline Model\n",
                "        - Vamos criar um modelo base para comparar com o modelo que vamos construir\n",
                "    - Model Type Selection\n",
                "        - Vamos escolher o melhor tipo de modelo para o problema\n",
                "        - Escolhemos alguns modelos dessa classe para comparar com o modelo base\n",
                "- Model Training\n",
                "    - Baseline Training\n",
                "        - Vamos treinar os modelos escolhidos normalmente e verificar os resultados\n",
                "    - Cross Validation Training\n",
                "        - Vamos treinar os modelos escolhidos cada um com o método de Cross Validation para ver seu desempenho geral no dataset\n",
                "        - A divisão em treino e teste feita por nós é apenas um dos jeitos de se fazer a divisão do dataset, o modelo pode performar muito bem ou muito mal na divisão que fizemos\n",
                "        - Por isso que executamos o Cross Validation, para avaliar o desempenho do modelo no dataset geral, com várias possibilidades de divisões em treino e teste sendo testadas e calculando a média do desempenho em cada uma"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Model Building Checkpoint"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Fazendo um checkpoint, carregamos o dataframe para uma nova variável, isolando os resultados obtidos nesta seção dentro dela e evitando propagações de erros que requeiram a reexecução do notebook inteiro."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_dataset = load_dataset('Dataset_Model')\n",
                "model_dataset.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_dataset.dtypes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_dataset[\"date\"] = pd.to_datetime(model_dataset[\"date\"])\n",
                "model_dataset.dtypes"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Train-Test Splitting"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Vamos separar o dataset final em treino e teste, descartando as variáveis resposta, e também em treino de Cross Validation, neste caso preservando as variáveis resposta.\n",
                "\n",
                "Vamos especificar qual é a variável resposta quando o Cross Validation for usado."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# training dataset\n",
                "X_train = model_dataset[model_dataset['date'] < '2015-06-05']\n",
                "y_train = X_train['sales']\n",
                "# test dataset\n",
                "X_test = model_dataset[model_dataset['date'] >= '2015-06-05']\n",
                "y_test = X_test['sales']\n",
                "# Cross validation training/testing dataset, uses all the features, including the target variable\n",
                "# We'll specify the target variable in the cross val function\n",
                "X_Cross = model_dataset[cross_val_cols]\n",
                "# Minimun and maximum date for the Train and Test dataset\n",
                "Train_min_date, Train_max_date = X_train['date'].min(), X_train['date'].max()\n",
                "Test_min_date, Test_max_date = X_test['date'].min(), X_test['date'].max()\n",
                "# Drop the target variable 'sales' and future variable 'date' from the XTrain dataframe\n",
                "# In order to do not train with it\n",
                "# Also drop every other column that is not needed for the model, using the filter 'feature_selection_cols'\n",
                "X_train = X_train[feature_selection_cols]\n",
                "X_test = X_test[feature_selection_cols]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f'Training Min Date: {Train_min_date}')\n",
                "print(f'Training Max Date: {Train_max_date}')\n",
                "\n",
                "print(f'\\nTest Min Date: {Test_min_date}')\n",
                "print(f'Test Max Date: {Test_max_date}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Com isso temos 3 datasets:\n",
                "- Treino\n",
                "    - X_train: Variáveis de treino\n",
                "    - y_train: Variável única de resposta do treino\n",
                "    - Estes datasets passam pelo treinamento do modelo normal\n",
                "- Teste\n",
                "    - X_test: Variáveis de teste\n",
                "    - y_test: Variável única de resposta do teste\n",
                "    - Estes datasets não passam pelo treinamento do modelo, ficando intocados até o final\n",
                "- Cross Validation\n",
                "    - X_Cross: Variáveis de treino para o Cross Validation, incluindo a variável resposta e a variável de data\n",
                "    - A variável de data tem de estar presente pois temos uma série temporal como problema\n",
                "    - Este dataset passa pelo treinamento do modelo em Cross Validation"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Model Selection"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Vamos criar o modelo de baseline e escolher os modelos com os quais vamos trabalhar no dataset, dentro desta fase teremos dois tipos de treinamento:\n",
                "- Baseline Training\n",
                "    - Vamos treinar os modelos de modo normal, com os datasets de treino e teste\n",
                "- Cross Validation Training\n",
                "    - Vamos treinar os modelos no modo de Cross Validation, com o dataset de crossval, e verificar o desempenho real no dataset"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Baseline Training"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### Baseline Model"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Nosso modelo de baseline será o Average Model, que retorna a média de vendas que uma loja teve em todo o período registrado."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "baseline_X = X_test.copy()\n",
                "baseline_X['sales'] = y_test.copy()\n",
                "\n",
                "# prediction\n",
                "baseline_Y = baseline_X[['store', 'sales']].groupby('store').mean().reset_index().rename(columns={'sales': 'predictions'})\n",
                "baseline_Y.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Com a predição de média feita, vamos juntar os datasets de treino e teste, e verificar o desempenho do modelo."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "baseline_model = pd.merge(baseline_X, baseline_Y, how='left', on='store')\n",
                "y_pred_baseline = baseline_model['predictions']\n",
                "\n",
                "# performance\n",
                "baseline_result = model_metrics('Average Model', y_test, y_pred_baseline, 'Exponential')\n",
                "baseline_result"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### Linear Regression Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# model\n",
                "#lnr_model = LinearRegression().fit(X_train, y_train)\n",
                "\n",
                "#prediction\n",
                "#ypred_lnr = lnr_model.predict(X_test)\n",
                "\n",
                "#performance\n",
                "#lnr_result = model_metrics('Linear Regression', y_test, ypred_lnr, 'Exponential')\n",
                "#save_model(lnr_model, 'Linear Regression')\n",
                "#lnr_result"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### Lasso Regression Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# model\n",
                "#lsr_model = Lasso(alpha=0.01).fit(X_train, y_train)\n",
                "\n",
                "# prediction\n",
                "#ypred_lsr = lsr_model.predict(X_test)\n",
                "\n",
                "# performance\n",
                "#lsr_result = model_metrics('Lasso Regression', y_test, ypred_lsr, 'Exponential')\n",
                "#save_model(lsr_model, 'Lasso Regression')\n",
                "#lsr_result"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### Random Forest Regressor Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# model\n",
                "#rfr_model = RandomForestRegressor(n_estimators=100, n_jobs=-1, random_state=42).fit(X_train, y_train)\n",
                "\n",
                "# prediction\n",
                "#ypred_rfr = rfr_model.predict(X_test)\n",
                "\n",
                "# performance\n",
                "#rfr_result = model_metrics('Random Forest Regressor', y_test, ypred_rfr, 'Exponential')\n",
                "#save_model(rfr_model, 'Random Forest Regressor')\n",
                "#rfr_result"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### XGBoost Regressor Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# model\n",
                "xgbr_model = XGBRegressor(objective='reg:squarederror', n_estimators=100, eta=0.01, max_depth=10,\n",
                "                            subsample=0.7, colsample_bytee=0.9).fit(X_train, y_train)\n",
                "\n",
                "# prediction\n",
                "ypred_xgbr = xgbr_model.predict(X_test)\n",
                "\n",
                "# performance\n",
                "xgbr_result = model_metrics('XGBoost Regressor', y_test, ypred_xgbr, 'Exponential')\n",
                "#save_model(xgbr_model, 'XGBoost Regressor')\n",
                "xgbr_result"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#import gc\n",
                "#gc.collect()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Cross Validation Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Image(filename='..\\\\..\\\\Assets\\\\Images\\\\Time_series_training.png', width=1000, height=500)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### Linear Regression Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#lnr_result_cv = crossval_time_series(X_Cross, 5, 8, 'Linear Regression', lnr_model, (['date', 'sales'],['sales']), verbose = True)\n",
                "\n",
                "#lnr_result_cv"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### Lasso Regression Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#lsr_result_cv = crossval_time_series(X_Cross, 5, 8, 'Lasso Regression', lsr_model, (['date', 'sales'],['sales']), verbose = True)\n",
                "\n",
                "#lsr_result_cv"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### Random Forest Regressor Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#rfr_result_cv = crossval_time_series(X_Cross, 5, 8, 'Random Forest Regressor', rfr_model, (['date', 'sales'],['sales']), verbose = True)\n",
                "\n",
                "#rfr_result_cv"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### XGBoost Regressor Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#xgbr_result_cv = crossval_time_series(X_Cross, 5, 8, 'XGBoost Regressor', xgbr_model, (['date', 'sales'],['sales']), verbose = True)\n",
                "\n",
                "#xgbr_result_cv"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#import gc\n",
                "#gc.collect()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Models Performance"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### Baseline Training Comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#modelling_result = pd.concat([baseline_result, lnr_result, lsr_result, rfr_result, xgbr_result])\n",
                "#modelling_result"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Image(filename='..\\\\..\\\\Assets\\\\Images\\\\Baseline_Training_Comparison.png', width=700, height=180)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### Cross Validation Training Comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#modelling_result_cv = pd.concat([lnr_result_cv, lsr_result_cv, rfr_result_cv, xgbr_result_cv])\n",
                "#modelling_result_cv"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Image(filename='..\\\\..\\\\Assets\\\\Images\\\\Cross_Validation_Training_Comparison.png', width=900, height=170)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Model Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Image(filename='..\\\\..\\\\Assets\\\\Images\\\\Model Evaluation.png', width=200, height=100)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Nesta fase avaliamos o desempenho dos modelos escolhidos e alteramos seus parâmetros para maximizar o desempenho. Também escolhemos o melhor modelo para usar como modelo final desta análise.\n",
                "\n",
                "A Model Evaluation é composta de três partes:\n",
                "- Model Comparison\n",
                "    - Vamos comparar os modelos escolhidos com o modelo base e verificar qual tem o melhor desempenho geral no dataset, resultado obtido no desempenho do cross validation\n",
                "- Model Hyperparameter Fine Tuning\n",
                "    - Vamos alterar os parâmetros do modelo escolhido para melhorar o desempenho de acordo com algum algoritmo de otimização de parâmetros\n",
                "- Final Model Selection\n",
                "    - Vamos treinar o melhor modelo com os parâmetros finais escolhidos\n",
                "    - Este modelo será usado para prever os dados de teste\n",
                "    - Este modelo será salvo em um arquivo binário .pkl para uso posterior"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Model Evaluation Checkpoint"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Fazendo um checkpoint, copiamos o dataframe para uma nova variável, isolando os resultados obtidos nesta seção dentro dela e evitando propagações de erros que requeiram a reexecução do notebook inteiro."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# df5 = df4.copy()\n",
                "#print(\"Checkpoint successful\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# df5.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Model Hyperparameter Fine Tuning"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Nesta fase buscamos encontrar a melhor combinação de parâmetros possíveis para maximizar o aprendizado e o desempennho do modelo.\n",
                "\n",
                "A fase de hyperparameter tuning pode ser feita de três formas:\n",
                "- Random Search\n",
                "    - Define valores aleatórios para os parâmetros do modelo\n",
                "    - Veloz, porém não testa todas as combinações de parâmetros possíveis\n",
                "- Grid Search\n",
                "    - Define todas as combinações possíveis de parâmetros para o modelo\n",
                "    - Extremamente lento, mas testa todas as combinações de parâmetros possíveis\n",
                "    - Sempre chega ao melhor resultado possível\n",
                "- Bayesian Search\n",
                "    - Intermediário entre os dois, é mais lento que o Random Search, mas mais rápido que o Grid Search\n",
                "        - Define os valores de parâmetros do modelo com base na teoria de Bayes\n",
                "    - Busca os melhores parâmetos futuros com base nos resultados de cada treinamento anterior"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Random Search"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Vamos utilizar o Random Search para encontrar a melhor combinação de parâmetros para o modelo. \n",
                "- Um bom número de ciclos de busca é 10\n",
                "- Quanto maior o número de estimadores, mais demorado o processo de busca"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "param = {\n",
                "    'n_estimators': [150, 170, 250, 300, 350],#[1500, 1700, 2500, 3000, 3500]\n",
                "    'eta': [0.01, 0.03],\n",
                "    'max_depth': [3, 5, 9],\n",
                "    'subsample': [0.1, 0.5, 0.7],\n",
                "    'colsample_bytree': [0.3, 0.7, 0.9],\n",
                "    'min_child_weight': [3, 8, 15]\n",
                "        }\n",
                "\n",
                "cycles = 3 #3"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "random_search_tms(cycles, X_Cross, 5, 8, 'XGBoost Regressor tuned', (['date', 'sales'],['sales']), verbose = True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Hyperparameter Evaluation"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "A melhor métrica para definir o modelo que mais se adequa ao dataset de modo genérico (com cross validation) é o RMSE, ou seja, o erro quadrático médio (root mean squared error).\n",
                "- No caso desta análise, com 3 ciclos de busca vimos que no primeiro ciclo o modelo já obteve o melhor resultado, com o menor RMSE entre todos os modelos testados\n",
                "- Com RMSE de **2588.24 +/- 96.08**, o menor entre todos (4678.03 e 3941.8)\n",
                "    - E com os parâmetros:\n",
                "    - **n_estimators:** 350\n",
                "    - **eta:** 0.03\n",
                "    - **max_depth:**\t3\n",
                "    - **subsample:** 0.5\n",
                "    - **colsample_bytree:** 0.9\n",
                "    - **min_child_weight:** 15"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Image(filename='..\\\\..\\\\Assets\\\\Images\\\\Random_search_3_cycles_training.png', width=1500, height=160)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Final Model"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "O modelo final só surge após o treinamento do modelo com todos os parâmetros finais otimizados.\n",
                "- Os testes de desempenho já foram feitos na fase de Cross Validation \n",
                "    - O modelo X foi o melhor por ter o menor RMSE entre todos\n",
                "- Os parâmetros finais foram descobertos na fase de Random Search\n",
                "- Ele será treinado e refinado com esses parâmetros escolhidos\n",
                "- Vamos fazer uma predição para o dataset de teste (y_test) para testar seu desempenho final de negócio\n",
                "- Então vamos salvar o modelo em um arquivo binário .pkl para uso posterior no Deployment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "param_tuned =   {\n",
                "                'objective':'reg:squarederror',\n",
                "                'n_estimators': 3000,\n",
                "                'eta': 0.03,\n",
                "                'max_depth': 5,\n",
                "                'subsample': 0.7,\n",
                "                'colsample_bytree': 0.7,\n",
                "                'min_child_weight': 3 \n",
                "                }"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# model\n",
                "model_xgbr_tuned = XGBRegressor(**param_tuned).fit(X_train,y_train)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# saving tuned model\n",
                "save_model(model_xgbr_tuned, 'XGBoost_Regressor_Tuned')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import gc\n",
                "gc.collect()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Metrics Interpretation"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Nesta fase vamos entender quais são as métricas de erro usadas em Data Science e quais os seus usos principais."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Temos 5 principais métricas de erro para avaliar o desempeho de um modelo em Data Science, e 3 curvas de desempenho:"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Business Metrics"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- MAE - Mean Absolute Error\n",
                "    - Atribui peso igual a todos os erros\n",
                "    - Robusto na presença de outliers, não afetam tanto o resultado\n",
                "    - Fácil entendimento pelo time de negócios\n",
                "    - Toda vez que fizermos uma predição, estamos errando na média em 500 dólares pra cima ou pra baixo\n",
                "- MAPE - Mean Absolute Percentage Error\n",
                "    - Erro percentual da predição, toda vez que fizermos uma predição, estamos errando em pelo menos 10% do valor predito\n",
                "    - Mostra o quão longe a predição está do valor real, na média, em porcentagem\n",
                "- Não podem ser usados quando a variável resposta contém zeros, precisando ser filtrados antes do cálculo"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Model Metrics"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Sensíveis a outliers, que afetam bastante o resultado\n",
                "- RMSE - Root Mean Squared Error\n",
                "    - Atribui maior peso aos erros maiores\n",
                "    - Por ser sensível a toda a gama de dados disponíveis, é considerado uma das melhores métricas de desempenho\n",
                "    - Quanto menor, melhor\n",
                "    - Ideal para medir a performance dos modelos de machine learning\n",
                "- RMSPE - Root Mean Squared Percentage Error\n",
                "    - Erro RMSE em porcentagem\n",
                "- MPE - Mean Percentage Error\n",
                "    - É uma métrica útil para avaliar pra qual lado mais pende a imprecisão do modelo, para cima ou para baixo nos resultados de negócio, ou seja, se falha mais prevendo o pior ou o melhor caso.\n",
                "    - Diz apenas se o modelo está mais pendente para subestimar ou superestimar o valor real\n",
                "    - Se for positivo, o modelo está superestimando, se for negativo, está subestimando o valor real\n",
                "    - Não pode ser usado quando a variável resposta contém zeros, precisando ser filtrados antes do cálculo\n",
                "- RMSEE - Root Mean Squared Error of Estimation\n",
                "    - Erro quadrático médio da predição, ou seja, essa métrica nos dá o erro da diferença de valores entre a predição e o valor real\n",
                "    - Usado para refinar a precisão das predições\n",
                "- Curvas de Desempenho\n",
                "    - ROC - ROC Curve\n",
                "    - LIFT - Lift Curve\n",
                "    - AUC - Area Under the ROC Curve"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_dataset = load_dataset('Dataset_Model') "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_dataset.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_dataset[['sales']].head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# training dataset\n",
                "X_train = model_dataset[model_dataset['date'] < '2015-06-05']\n",
                "y_train = X_train['sales']\n",
                "# test dataset\n",
                "X_test = model_dataset[model_dataset['date'] >= '2015-06-05']\n",
                "y_test = X_test['sales']\n",
                "\n",
                "X_train = X_train[feature_selection_cols]\n",
                "X_test = X_test[feature_selection_cols]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "final_model = load_model('XGBoost_Regressor_Tuned')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# prediction\n",
                "y_pred = final_model.predict(X_test)\n",
                "\n",
                "# performance\n",
                "final_model_result = model_metrics('XGBoost Regressor Tuned', y_test, y_pred, 'Exponential')\n",
                "\n",
                "#final_result = pd.DataFrame()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#concatenate the dataframes horizontally\n",
                "#final_result = pd.concat([final_result, modelling_result_cv], axis=1)\n",
                "#final_result = pd.concat([final_result, final_model_result])\n",
                "#final_result.set_index('Model Name', inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#final_result\n",
                "final_model_result"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### MAE e MAPE"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Primeiro vamos ver qual o máximo e mínimo da nossa variável resposta para descobrir qual sua faixa(range) de valores."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(np.expm1(y_test).min(), np.expm1(y_test).max())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Range da variável resposta:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.expm1(y_test).max()-np.expm1(y_test).min()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#final_result\n",
                "final_model_result"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Se temos um MAE de 779, quanto % isso representa do nosso range da variável resposta?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(str(round(779/41000 * 100, 2)) + '%')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Se temos um MAE de 665, quanto % isso representa do nosso valor médio variável resposta?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.expm1(y_test).mean()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(str(round(779/np.expm1(y_test).mean() * 100, 2)) + '%')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Em média fazemos vendas de 7016 dólares, e pra cada predição que fizermos, temos um erro de 665 dólares, que é cerca de 11% deste valor.\n",
                "\n",
                "O MAPE é a representação em porcentagem do MAE."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### RMSE e MPE"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Métricas mais usadas para avaliar o desempenho do modelo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#final_result\n",
                "final_model_result"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(str(round(1096/np.expm1(y_test).mean() * 100, 2)) + '%')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Isso signifca que, considerando todos os valores do dataset, inclusive os outliers, o modelo está errando em 15.62% dos casos na sua previsão do valor real.\n",
                "\n",
                "O que significa que está acertando em 84.38% dos casos, considerando apenas esta métrica."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "O MPE é negativo, o que indica que o valor predito tende a ser maior do que o valor real, ou seja, o ponto fraco do modelo é no melhor caso."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Deployment Phase"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Image(filename='..\\\\..\\\\Assets\\\\Images\\\\Deployment Phase.png', width=250, height=100)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Visualization and Dashboard"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Image(filename='..\\\\..\\\\Assets\\\\Images\\\\Visualization and Dashboard.png', width=200, height=100)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Visualization and Dashboard Checkpoint"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Fazendo um checkpoint, copiamos o dataframe para uma nova variável, isolando os resultados obtidos nesta seção dentro dela e evitando propagações de erros que requeiram a reexecução do notebook inteiro."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# df7 = df6.copy()\n",
                "#print(\"Checkpoint successful\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# df7.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Performance assessment"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Como avaliamos a performance do modelo contra a performance do negócio? Isto é, conseguimos melhorias de desempenho com o modelo? Como aferir isso? É nesta fase que verificamos se todo o treinamento e refinamento do modelo valeram a pena em relação ao que já tinhamos previamente do negócio."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Performance Features"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Para avaliar a performance do modelo vamos criar algumas colunas extras no dataset final"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_dataset.shape, y_pred.shape"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Como podemos ver, o dataset final tem muito mais linhas do que o de predição, isso porque a predição só trata das últimas 8 semanas, na coluna Data do dataset final.\n",
                "para podermos fundir a coluna de predição com o dataset final e formar o dataset de visualização vamos ter que descartar as linhas as quais não temos dados de predição, ou seja, as linhas que foram usadas para treino.\n",
                "\n",
                "Isso equivale a chamar nosso novo dataset de visualização como o dataset que fora usado para treino nos passos anteriores.\n",
                "\n",
                "Vamos checar a quantidade de linha dos dois para confirmar."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_dataset.shape, y_pred.shape, X_test.shape"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Como suspeitamos, as linhas são idênticas na coluna de predição e de teste. Então nosso dataset de visualização precisa ser exatamente igual a coluna que foi de teste dos modelos. \n",
                "É o que faremos agora.\n",
                "Este foi o filtro que usamos para gerar a coluna de teste:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"X_test = model_dataset[model_dataset['date'] >= '2015-06-05']\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "E é o que vamos usar agora no model_dataset para criar o de visualização."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# viz_dataset\n",
                "viz_dataset = model_dataset[model_dataset['date'] >= '2015-06-05'] #previously X_test"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "viz_dataset[['sales']].head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "y_pred.shape, viz_dataset.shape"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Vamos regredir o scaling da variável resposta para o valor real, pois assim a visualização dos gráficos não ficará distorcida e com valores baixos demais.\n",
                "\n",
                "Nós rescalamos quando vamos treinar e predizer, mas retornamos ao valor real da variável resposta quando vamos avaliar métricas do modelo e visualizar o desempenho final."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# rescale target variable\n",
                "viz_dataset['sales'] = np.expm1(viz_dataset['sales'])\n",
                "viz_dataset['predictions'] = np.expm1(y_pred)\n",
                "viz_dataset['error_pred'] = viz_dataset['sales'] - viz_dataset['predictions']\n",
                "viz_dataset['error_rate'] = viz_dataset['predictions']/viz_dataset['sales']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# get predictions\n",
                "viz_dataset[['sales','predictions','error_pred','error_rate']].sample(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "viz_cols = Flexlist(viz_dataset.columns.tolist())\n",
                "print(viz_cols, type(viz_cols) )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "list_indexer(viz_cols)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ordered_vis_cols = viz_cols[[21,0,1,2,3,4,22,23,24,25]]\n",
                "print(ordered_vis_cols)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Model Performance"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Para isto, o poblema de negócio já deve ter algum tipo de métrica de previsão anterior, por ela será possível avaliar o desempenho do modelo. Como neste caso não temos algo vindo diretamente do negócio, vamos usar o modelo de baseline assumindo que ele já veio pronto com o problema e também as métricas do modelo para prever incrementos de receita junto com melhor e pior caso."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### Baseline vs Model Performance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# dataframe with baseline_results and tuned_results\n",
                "\n",
                "model_performance = pd.concat([baseline_result, final_model_result], axis=0)\n",
                "model_performance.sort_values(by='RMSE', ascending=False, inplace=True)\n",
                "model_performance.set_index('Model Name', inplace=True)\n",
                "model_performance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.suptitle('Model Metrics')\n",
                "plt.subplot(2, 2, 1)\n",
                "plt.title('RMSE Comparison')\n",
                "sns.barplot(x = model_performance.index, y = 'RMSE', data = model_performance)\n",
                "plt.subplot(2, 2, 2)\n",
                "plt.title('MAE Comparison')\n",
                "sns.barplot(x = model_performance.index, y = 'MAE', data = model_performance)\n",
                "plt.subplot(2, 2, 3)\n",
                "plt.title('MAPE Comparison')\n",
                "sns.barplot(x = model_performance.index, y = 'MAPE', data = model_performance)\n",
                "plt.subplot(2, 2, 4)\n",
                "plt.title('MPE Comparison')\n",
                "sns.barplot(x = model_performance.index, y = 'MPE', data = model_performance)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Vamos ver a distribuição do erro por predição:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize = (20,10))\n",
                "plt.suptitle('Error by prediction distribution')\n",
                "sns.distplot(viz_dataset['error_pred'])\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Model Performance in Business"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Business Performance Gain"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Aqui vamos ver o que o modelo fez para melhorar o desempenho do negócio, fazendo uma previsão geral de receita para toda a rede de lojas."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Temos o melhor e pior cenário de vendas de toda a rede de lojas, somando todas as lojas, nas próximas 8 semanas."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Como os dados nos mostram, o modelo final é consideravelmente melhor que o modelo de baseline, chegando a cortar em quase metade o RMSE quando comparado com o mesmo, e o superando também em todas as outras métricas.\n",
                "\n",
                "Com isto concluimos que após a análise feita, as features selecionadas, o modelo treinado e seus parâmetros refinados, que o modelo final tem maior taxa de sucesso que o método usado anteriormente na predição de vendas."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## API development"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Image(filename='..\\\\..\\\\Assets\\\\Images\\\\Webapp Deployment.png', width=200, height=100)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### API development Checkpoint"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Fazendo um checkpoint, copiamos o dataframe para uma nova variável, isolando os resultados obtidos nesta seção dentro dela e evitando propagações de erros que requeiram a reexecução do notebook inteiro."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# df6 = df5.copy()\n",
                "#print(\"Checkpoint successful\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# df6.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Prediction Class"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Na classe em produção vão ser incluídas as fases:\n",
                "- Data Collection\n",
                "- Data Cleaning\n",
                "    - Todas as fases, pois modificam o dataset diretamente\n",
                "- Feature Engineering\n",
                "    - Data Preparation\n",
                "        - Numerical Variable Treatment\n",
                "        - Categorical Variable Treatment\n",
                "        - Cyclic Variable Treatment\n",
                "        - Target Variable Treatment\n",
                "        - Encoded dataset\n",
                "    - Feature Selection\n",
                "        - Best Features\n",
                "        - Final Dataset Storage\n",
                "- Model Building\n",
                "    - Train-Test Splitting\n",
                "    - Model Selection\n",
                "- Model Evaluation\n",
                "    - Model Hyperparameter Fine Tuning\n",
                "    - Final Model\n",
                "- API\n",
                "    - FastAPI\n",
                "    - Routes\n",
                "    - Predict route\n",
                "    - Predict function\n",
                "    - Model import with pickle\n",
                "    - jsonify function\n",
                "    - pipeline function"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### API Handler"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Nesta seção vamos criar o handler que vai ser responsável por fazer a chamada da API.\n",
                "Nossa API terá dois endpoints:\n",
                "- /predict\n",
                "    - Recebe um JSON o número direto da loja a se prever as vendas\n",
                "- /telegram\n",
                "    - Recebe um JSON com os dados da requisição ou o número direto da loja a se prever as vendas"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import pickle\n",
                "import pandas as pd\n",
                "import requests\n",
                "import json\n",
                "from flask import Flask, request, Response, render_template, abort, redirect\n",
                "#from folder.file import class\n",
                "from Store_Sales_Analysis import Store_Sales_Analysis\n",
                "# get token from .env file\n",
                "token = os.environ.get('Token')\n",
                "\n",
                "def set_webhook_telegram(url = None, token = None):\n",
                "    url = url + token\n",
                "    url = url + '/setWebhook?url=' + url\n",
                "    api_call = requests.post(url)\n",
                "    print(f'Status Code {api_call.status_code}')\n",
                "    return None\n",
                "\n",
                "def send_message(chat_id = None, text = None, token = None):\n",
                "    url = f'https://api.telegram.org/bot{token}/'\n",
                "    url = url + f'sendMessage?chat_id={chat_id}'\n",
                "    \n",
                "    api_call = requests.post(url, json = {'text': text })\n",
                "    print(f'Status Code {api_call.status_code}')\n",
                "    \n",
                "    return None\n",
                "\n",
                "#middleware\n",
                "def get_prediction(data):\n",
                "    # API Call\n",
                "    # makes an API call to /predict endpoint\n",
                "    url_prod = 'https://andrew-store-sales-analysis.herokuapp.com/predict'\n",
                "    dev_url = 'http://127.0.0.1:8000/predict'\n",
                "    #port = os.environ.get('PORT', 8000)\n",
                "    #'http://localhost:5000/register'\n",
                "    url = url_prod\n",
                "    header = {'Content-type': 'application/json'}\n",
                "    #data = data\n",
                "    \n",
                "    api_call = requests.post(url, data = data, headers = header)\n",
                "    \n",
                "    print(f'Status Code {api_call.status_code}')\n",
                "    \n",
                "    #return str(str(api_call.status_code) + ' ' + str(api_call.text) + 'HERE')\n",
                "    prediction = pd.DataFrame(api_call.json(), columns = api_call.json()[0].keys())\n",
                "    #return api_call.json()\n",
                "    return prediction\n",
                "\n",
                "def load_model(model_name):\n",
                "    # loading model in readbytes mode\n",
                "    current_path = os.path.dirname(os.path.abspath(__file__))\n",
                "    model = pickle.load(open(current_path + model_name + '.pkl', 'rb'))\n",
                "    \n",
                "    return model\n",
                "\n",
                "def load_dataset(store_id):\n",
                "    # loading test dataset\n",
                "    try:\n",
                "        df_test_raw = pd.read_csv('test.csv')\n",
                "        df_store_raw = pd.read_csv('store.csv')\n",
                "        \n",
                "    except Exception as e:\n",
                "        print('error loading datasets')\n",
                "        print(e)\n",
                "    # merge test dataset + store\n",
                "    df_test = pd.merge(df_test_raw, df_store_raw, how = 'left', on = 'Store')\n",
                "    \n",
                "    # choose store for prediction\n",
                "    df_test = df_test[df_test['Store'] == store_id]\n",
                "    \n",
                "    if not df_test.empty:\n",
                "        # remove closed days\n",
                "        df_test = df_test[df_test['Open'] != 0]\n",
                "        df_test = df_test[~df_test['Open'].isnull()]\n",
                "        df_test = df_test.drop('Id', axis = 1)\n",
                "        # convert Dataframe to json\n",
                "        data = json.dumps(df_test.to_dict(orient = 'records'))\n",
                "        \n",
                "    else:\n",
                "        data = 'error'\n",
                "        \n",
                "    return data\n",
                "\n",
                "def parse_message(message = None):\n",
                "    \n",
                "    chat_id = message['message']['chat']['id']\n",
                "    store_id = message['message']['text']\n",
                "    store_id = store_id.replace('/', '')\n",
                "    # if store_id is /start send store_id = '/start' to treat that later\n",
                "    try:\n",
                "        store_id = int(store_id)\n",
                "        \n",
                "    except ValueError:\n",
                "        print('Store id needs to be a number')\n",
                "        store_id = 'error'\n",
                "        \n",
                "    return chat_id, store_id\n",
                "\n",
                "def get_response(response, error = None, endpoint = None,  message_chat_id = None, message_text = None):\n",
                "    \n",
                "    #implement with match case with python 3.10\n",
                "    if response == 0: #debug one\n",
                "        message =  {'Keys': 'are ok',\n",
                "                    'message_chat_id': message_chat_id,\n",
                "                    'message_text': message_text,\n",
                "                    'endpoint': endpoint}\n",
                "    elif response == 1:\n",
                "        message =  {\"hello\": r\"Greetings, I am a telegram bot\",\n",
                "                    \"error\": r\"There are missing keys in the request\",\n",
                "                    \"instruction\": r\"Please send a json object with the following keys:\",\n",
                "                    \"message\": r\"{ chat: {id:chat_id, type:chat_type}, text:/some_text}\",\n",
                "                    \"goodbye\": f\"This proofs you could access the endpoint {endpoint}\"}\n",
                "    elif response == 2:\n",
                "        message = {\"error\": \"No data received, json empty, please send a valid json object\"}\n",
                "    elif response == 3:\n",
                "        message = {\"error\": \"No json received, data header doesn't indicate a json object, please send a json object\"}\n",
                "    elif response == 4:\n",
                "        message = {\"error\": \"Method not allowed\"}\n",
                "    elif response == 5:\n",
                "        message = {\"success\": \"Message sent to telegram chat successfully with prediction\"}\n",
                "    elif response == 6:\n",
                "        message =  {\"success\": \"Message sent to telegram chat successfully but no prediction was made\",\n",
                "                    \"error\": error}\n",
                "    elif response == 7:\n",
                "        # greetings message when /start is called\n",
                "        message = '''Hello! I am a telegram bot.\n",
                "                    I can predict the sales of a store.\n",
                "                    Please send me a store number or a table with values to predict the sales. \n",
                "                    '''\n",
                "        return message\n",
                "    \n",
                "    message = json.dumps(message)\n",
                "    \n",
                "    return message\n",
                "\n",
                "def check_json(data = None, endpoint = None, method = None):\n",
                "    \n",
                "    # check if request.content_type is json or if it is empty\n",
                "    if (data.content_type != '' and data.is_json): #check if data header indicates json and is not empty\n",
                "        # remove empty check in case telegram doesn't send correct headers with json type\n",
                "        # perhaps remove it entirely if telegram doesn't send headers at all\n",
                "        received_json = data.get_json()\n",
                "        # log json received\n",
                "        if any(received_json):\n",
                "            # check if required keys are in the json\n",
                "            # can add more later if needed\n",
                "            try:\n",
                "                message_chat_id = received_json['message']['chat']['id']\n",
                "                message_text = received_json['message']['text']\n",
                "                # log json not empty, keys are in the json\n",
                "                \n",
                "            except Exception as e:\n",
                "                # only error that can occur here is if some key doesn't exist\n",
                "                # log json not empty, error key not found\n",
                "                # return instructions\n",
                "                abort(Response(get_response(1, None, endpoint), status = 400, mimetype = 'application/json'))\n",
                "                \n",
                "            finally:\n",
                "                \n",
                "                if method == 'GET':\n",
                "                    # return instructions\n",
                "                    abort(Response(get_response(1, None, endpoint), status = 400, mimetype = 'application/json'))\n",
                "                    \n",
                "                else:\n",
                "                    \n",
                "                    # return json\n",
                "                    return received_json\n",
                "                # comment when deploying\n",
                "                # return abort(Response(get_response(0, None, endpoint, message_chat_id, message_text), status = 200, mimetype = 'application/json'))\n",
                "        else:\n",
                "            # return error, json is empty\n",
                "            abort(Response(get_response(2), status = 400, mimetype = 'application/json'))\n",
                "    else:\n",
                "        # return error, data header doesn't indicate a json object\n",
                "        abort(Response(get_response(3), status = 400, mimetype = 'application/json'))\n",
                "\n",
                "def check_entrypoint(call = None, endpoint = None):\n",
                "    \n",
                "    if endpoint in ['/telegram', '/webapp']:\n",
                "        # external endpoint, need to check if method is GET, POST or other\n",
                "        if call.method == 'POST':\n",
                "            #log post method requested\n",
                "            call_json = check_json(request, endpoint, 'POST')\n",
                "            \n",
                "            return call_json\n",
                "            \n",
                "        elif call.method == 'GET':\n",
                "            #log get method requested\n",
                "            check_json(request, endpoint, 'GET')\n",
                "            \n",
                "        else:\n",
                "            # log other method requested\n",
                "            # return method not allowed\n",
                "            abort(Response(get_response(4), status = 400, mimetype = 'application/json'))\n",
                "            \n",
                "    elif endpoint == '/predict':\n",
                "        \n",
                "        if call.method == 'GET':\n",
                "            # return instructions\n",
                "            abort(Response(get_response(1, None, endpoint), status = 400, mimetype = 'application/json'))\n",
                "        # internal endpoint, no need to check method\n",
                "        call_json = call.get_json()\n",
                "        \n",
                "        return call_json\n",
                "    \n",
                "# API initialization\n",
                "app = Flask(__name__, static_folder='static')\n",
                "\n",
                "@app.route('/')\n",
                "@app.route('/home')\n",
                "def home():\n",
                "    \n",
                "    return render_template('index.html')\n",
                "\n",
                "@app.route('/webapp')\n",
                "def webapp():\n",
                "    \n",
                "    return '<p> Welcome to the webapp </p>'\n",
                "    # return render_template('webapp.html')\n",
                "\n",
                "@app.route('/telegram', methods = ['GET', 'POST'])\n",
                "def telegram_bot():\n",
                "    \n",
                "    received_json = check_entrypoint(request, endpoint = '/telegram')\n",
                "    \n",
                "    chat_id, store_id = parse_message(received_json)\n",
                "    #third: command\n",
                "    if store_id != 'error':\n",
                "        # loading data\n",
                "        data = load_dataset(store_id)\n",
                "        \n",
                "        # if not returned an empty dataset (string 'error') because store_id doesn't exist\n",
                "        if data != 'error':\n",
                "            # prediction call\n",
                "            prediction_df = get_prediction(data)\n",
                "            # calculation\n",
                "            pred_group_df = prediction_df[['store', 'prediction']].groupby('store').sum().reset_index()\n",
                "            # get store number\n",
                "            store = pred_group_df['store'].values[0]\n",
                "            # get prediction value\n",
                "            prediction = pred_group_df['prediction'].values[0]\n",
                "            # convert to number\n",
                "            prediction = float(prediction)\n",
                "            # send message with store number and prediction in text format to telegram bot chat\n",
                "            msg = f'Store Number {store} will sell R${prediction:,.3f} in the next 8 weeks'\n",
                "            \n",
                "            #print(msg)\n",
                "            send_message(chat_id, msg, token)\n",
                "            # return message sent to telegram chat, in this case, success\n",
                "            return Response(get_response(5), status =200)\n",
                "        \n",
                "        else: #command\n",
                "            error = 'Store Not Available'\n",
                "            send_message(chat_id, error, token)\n",
                "            # return message sent to telegram chat, in this case, error\n",
                "            return Response(get_response(6, error = error), status =200)\n",
                "        \n",
                "    else:\n",
                "        error = 'Store ID must be a number'\n",
                "        send_message(chat_id, error, token)\n",
                "        # return message sent to telegram chat, in this case, error\n",
                "        return Response(get_response(6, error = error), status =200)\n",
                "\n",
                "@app.route('/predict', methods = ['GET', 'POST'])\n",
                "def model_predict():\n",
                "    \n",
                "    received_json = check_entrypoint(request, endpoint = '/predict')\n",
                "    \n",
                "    model = load_model('/static/models/XGBoost_Regressor_Tuned')\n",
                "    \n",
                "    # redo this later, strange check (?). Must be a better way to do this\n",
                "    if isinstance(received_json, dict): # unique example\n",
                "        \n",
                "        X_test = pd.DataFrame(received_json, index = [0])\n",
                "        \n",
                "    else: # multiple example\n",
                "        X_test = pd.DataFrame(received_json, columns = received_json[0].keys())\n",
                "    \n",
                "    pipeline = Store_Sales_Analysis()\n",
                "    \n",
                "    data_cleaned = pipeline.data_cleaning(X_test)\n",
                "    \n",
                "    feature_extracted = pipeline.feature_extraction(data_cleaned)\n",
                "    \n",
                "    data_prepared = pipeline.data_preparation(feature_extracted)\n",
                "    \n",
                "    prediction = pipeline.get_prediction(model, X_test, data_prepared)\n",
                "    \n",
                "    #return prediction\n",
                "    return Response(prediction, status = 200, mimetype = 'application/json')\n",
                "\n",
                "if __name__ == '__main__':\n",
                "    port = os.environ.get('PORT', 8000)\n",
                "    host_prod = os.environ.get('HOST', '0.0.0.0')\n",
                "    app.run(host = host_prod, port = port)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### API Tester"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Vamos simular uma chamada de API do jeito que ela funcionaria no app final aqui no Notebook de Análise"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Primeiro, carregamos os dataframes com os dados de cada loja.\n",
                "- Depois, carregamos o dataframe de teste com dados ainda não vistos pelo modelo."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# loading test dataset\n",
                "df_test = pd.read_csv(\"A:\\Andrew\\Desenvolvimento\\Portfolio\\Backup\\Store Sales Analysis\\Development\\Data\\Dataset\\Raw\\test.csv\")\n",
                "# merge test dataset + store\n",
                "df_request = pd.merge(df_test, df_store_raw, how = 'left', on = 'Store')\n",
                "\n",
                "# choose store for prediction\n",
                "df_request = df_request[df_request['Store'].isin([40, 22, 41])]\n",
                "\n",
                "# remove closed days\n",
                "df_request = df_request[df_request['Open'] != 0]\n",
                "df_request = df_request[~df_request['Open'].isnull()]\n",
                "df_request = df_request.drop('Id', axis = 1)\n",
                "# convert Dataframe to json\n",
                "data = json.dumps(df_request.to_dict(orient = 'records'))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Agora fazemos a chamada da API, passando o número da loja ou o JSON com os dados da requisição.\n",
                "- A chamada deve funcionar tanto localmente quanto no Heroku."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# API Call\n",
                "url_local = 'http://0.0.0.0:5000/predict'\n",
                "url_api = 'https://andrew-store-sales-analysis.herokuapp.com/predict'\n",
                "header = {'Content-type': 'application/json' } \n",
                "data = data\n",
                "\n",
                "response = requests.post(url_api, data = data, headers = header)\n",
                "print('Status Code {}'.format(r.status_code))\n",
                "df_response = pd.DataFrame(response.json(), columns = response.json()[0].keys())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "d2 = df_response[['store', 'prediction']].groupby('store').sum().reset_index()\n",
                "\n",
                "for i in range(len(d2)):\n",
                "    print('Store Number {} will sell R${:,.2f} in the next 6 weeks'.format(\n",
                "            d2.loc[i, 'store'], \n",
                "            d2.loc[i, 'prediction']))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Web App"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Web App Checkpoint"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Frontend"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Timer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Notebook Start:\", str(Start).split(' ')[1].split('.')[0])\n",
                "      #log.info(\"Notebook Start =\", now)\n",
                "End = datetime.datetime.now() # time object\n",
                "print(\"Notebook End:\", str(End).split(' ')[1].split('.')[0])\n",
                "Execution = End - Start\n",
                "print(\"Execution Time:\", str(Execution).split('.')[0]) "
            ]
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "b666dbd1e057f0ca48c422280120603a43e4393a276013d976aedff41ddbe8cd"
        },
        "kernelspec": {
            "display_name": "Python 3.8.5 ('Data_Science')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
